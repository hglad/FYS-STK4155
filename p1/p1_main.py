from proj1_funcs import *
plt.rcParams.update({'font.size': 14})

"""
Perform OLS with data generated by the Franke function, without resampling.
Then find the confidence interval of beta for p = 5.
"""
def main(dataset='Terrain',n=50,method='ridge',p5_case=False):
    # np.random.seed(6)
    np.random.seed(10)
    print ("Dataset:", dataset)
    print ("Method:", method)

    # Determine dataset to analyze
    if (dataset == 'Franke'):
        x, y, z = Franke_dataset(n, noise=0.5)
        nx = n
        ny = n
    else:
        z = DataImport('Norway_1arc.tif', sc=20)
        z = z/np.max(z)
        # print (z.shape)
        nx = len(z[0,:])
        ny = len(z[:,0])
        x = np.linspace(0,1,nx)
        y = np.linspace(0,1,ny)
        x, y = np.meshgrid(x, y)

    z_1d = np.ravel(z)

    # p = 5 case
    if (p5_case == True):
        # Create design matrix, find beta, perform prediction for p = 5
        # z_1d = np.ravel(FrankeFunction(x,y))
        X = CreateDesignMatrix_X(x, y, 5)
        beta = np.linalg.pinv(np.dot(X.T, X)) .dot(X.T) .dot(z_1d)
        z_pred = X @ beta

        if (dataset == 'Franke'):
            z_1d = np.ravel(FrankeFunction(x,y))

        R2 = metrics.r2_score(z_1d, z_pred)
        MSE = metrics.mean_squared_error(z_1d, z_pred)
        print (R2, MSE)
        # plot_surf(x,y,z,cm.viridis,alpha=0.25)
        # plot_points(x,y,z_pred)
        # plt.show()

        # Variance of beta
        var_beta = np.diag(np.linalg.pinv(np.dot(X.T, X)) * np.var(z_1d))
        # CI for beta
        # CI(beta, np.sqrt(var_beta), nx, ny, p=5)

    # Define ranges for complexity and parameters
    min_p = 0;  max_p = 20
    min_param = 5e-6; max_param = 1e-2
    # 5e-6 lowest param for terrain, lasso
    # 1e-5 lowest param for franke, lasso
    n_params = 5

    if (method == 'ols'):
        n_params = 1   # only run once for OLS, parameter value does not matter

    polys = range(min_p,max_p)
    params = np.logspace(np.log10(min_param), np.log10(max_param), n_params)
    print (params)

    # Initialize arrays
    R2_scores,MSE_test,MSE_train,MSE_best_cv,error_test,bias_test,var_test,\
    error_train = (np.zeros((len(polys), n_params)) for i in range(8))

    # Perform cross-validation with given set of polynomials and parameters
    for i in range(len(params)):
        for j in range(len(polys)):
            R2_scores[j,i], MSE_test[j,i], MSE_train[j,i], error_test[j,i],  bias_test[j,i], var_test[j,i], error_train[j,i] = cross_validation(x, y, z, k=5, p=polys[j], dataset=dataset, param=params[i], method=method)
            print ("poly", j)
        print ("param", i)

    if (method == 'ols'):
        best_poly = polys[np.argmin(MSE_test[:,0])]
        best_param = 0      # just to assign a value
    else:
        min_mse_coords = np.argwhere(MSE_test==MSE_test.min())
        best_poly = polys[ min_mse_coords[0,0] ]
        best_param = params[ min_mse_coords[0,1] ]

    # plot_bias_var_err(polys, bias_test, var_test, error_test, error_train)
    plot_mse_train_test(polys, MSE_test, MSE_train, params, nx, ny)

    # best_poly = 53
    # best_param = 1e-9
    # Compare with true data if using Franke dataset
    if (dataset == 'Franke'):
        z = FrankeFunction(x,y)

    z_, z_pred = predict_poly(x,y,z,best_poly,best_param,method)

    # z_, z_pred = predict_poly(x,y,z,53,1e-9,method)
    z_pred_2d = np.reshape(z_pred, (ny,nx))

    plot_surf(x,y,z,color=cm.terrain, alpha=0.35)
    plot_pred(x,y,z_pred_2d)
    plt.show()

    print ("Polynomial degree with best MSE:", best_poly)
    if (method != 'ols'):
        print ("Param with best MSE: %1.3e" % best_param)

    print ("MSE:", metrics.mean_squared_error(z_, z_pred))
    print("R2:", metrics.r2_score(z_, z_pred))

# dataset = sys.argv[1]
# method = sys.argv[2]

main(method='ridge')

# mse_train vs mse_test plot:
# np.random.seed(6)
# noise = 0.5
# main(dataset='Franke',n=50,method='ols'), min_p = 0;  max_p = 15

# mse_train vs mse_test plot (ridge):
# np.random.seed(10)
# noise = 0.65
# main(dataset='Franke',n=50,method='ridge'), min_p = 0;  max_p = 15

# lasso-test with polynomials [30,40,num=10], params [5e-6; 1e-2, num=5]
# Polynomial degree with best MSE: 38
# Param with best MSE: 5.000e-06
# MSE: 0.012340358400887406
# R2: 0.560904773744191
