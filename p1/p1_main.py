from proj1_funcs import *
plt.rcParams.update({'font.size': 12})

"""
Perform OLS with data generated by the Franke function, without resampling.
Then find the confidence interval of beta for p = 5.
"""
# Franke_no_resampling(100)
def main(dataset='ridge',n=75,p=5,method='ols'):
    np.random.seed(123)
    # Determine dataset to analyze
    if (dataset == 'Franke'):
        x, y, z = Franke_dataset(n, noise=0.5)
    else:
        z = DataImport('Norway_1arc.tif', sc=10)
        nx = len(z[0,:])
        ny = len(z[:,0])
        x = np.linspace(0,1,nx)
        y = np.linspace(0,1,ny)
        x, y = np.meshgrid(x, y)

    z_1d = np.ravel(z)

    if (dataset == 'Franke'):
        # Create design matrix, find beta, perform prediction
        X = CreateDesignMatrix_X(x, y, p)
        beta = np.linalg.pinv(np.dot(X.T, X)) .dot(X.T) .dot(z_1d)
        z_pred = X @ beta

        R2 = metrics.r2_score(z_1d, z_pred)
        MSE = metrics.mean_squared_error(z_1d, z_pred)
        print (R2, MSE)

        # plot_surf(x,y,z,cm.viridis,alpha=0.25)
        # plot_points(x,y,z_pred)
        # plt.show()

        # Variance of beta
        var_beta = np.diag(np.linalg.pinv(np.dot(X.T, X)) * np.var(z_1d))

        # CI for beta
        CI(beta, np.sqrt(var_beta))

    # Perform cross-validation with a given range of polynomials and parameters
    min_p = 0;  max_p = 20
    polys = range(min_p,max_p)

    R2_scores,MSE_test,MSE_train,MSE_best_cv,error_test,bias_test,var_test,\
    error_train,bias_train,var_train = (np.zeros(len(polys)) for i in range(10))

    for j in range(len(polys)):
        R2_scores[j], MSE_test[j], MSE_train[j], error_test[j], bias_test[j], \
        var_test[j], error_train[j], bias_train[j], var_train[j] \
        = cross_validation(x, y, z, k=5, p=polys[j], param=1e-5, method=method)

    # plot_bias_var_err(polys, bias_test, var_test, MSE_test, bias_train, var_train, MSE_train)
    plot_mse_train_test(polys, MSE_test, MSE_train)


main()



#
